{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import cv2\n",
    "import os\n",
    "from scipy.ndimage import convolve\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data\n",
    "folders = ['triangle', 'star', 'square', 'circle']\n",
    "labels = []\n",
    "images = []\n",
    "for folder in folders:\n",
    "    for path in os.listdir('shapes/'+folder):\n",
    "        img = cv2.imread('shapes/'+folder+'/'+path,0)\n",
    "        images.append(cv2.resize(img, (60, 60)))\n",
    "        labels.append(folders.index(folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images:  12475\n",
      "Number of testimg images:  2495\n"
     ]
    }
   ],
   "source": [
    "#break data into training and test sets\n",
    "to_train= 0\n",
    "train_images, test_images, train_labels, test_labels = [],[],[],[]\n",
    "for image, label in zip(images, labels):\n",
    "    if to_train<5:\n",
    "        train_images.append(image)\n",
    "        train_labels.append(label)\n",
    "        to_train+=1\n",
    "    else:\n",
    "        test_images.append(image)\n",
    "        test_labels.append(label)\n",
    "        to_train = 0\n",
    "        \n",
    "print('Number of training images: ', len(train_images))\n",
    "print('Number of testimg images: ', len(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to flatten data\n",
    "def flatten(dimData, images):\n",
    "    images = np.array(images)\n",
    "    images = images.reshape(len(images), dimData)\n",
    "    images = images.astype('float32')\n",
    "    images /=255\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten data\n",
    "dataDim = np.prod(images[0].shape)\n",
    "train_data  = flatten(dataDim, train_images)\n",
    "test_data = flatten(dataDim, test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import linear_model, datasets, metrics\n",
    "\n",
    "# Models we will use\n",
    "logr = linear_model.LogisticRegression()\n",
    "rbm = BernoulliRBM(verbose=True)\n",
    "classifier = Pipeline(steps=[('rbm', rbm), ('logistic', logr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -2529.89, time = 38.06s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -888.15, time = 39.05s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -857.41, time = 39.27s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -909.72, time = 39.21s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -935.57, time = 39.13s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -929.72, time = 39.32s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -895.33, time = 39.16s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -919.56, time = 39.00s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -943.11, time = 39.02s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -900.73, time = 38.98s\n",
      "Logistic regression using RBM features:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       620\n",
      "          1       0.25      1.00      0.40       627\n",
      "          2       0.00      0.00      0.00       628\n",
      "          3       0.00      0.00      0.00       620\n",
      "\n",
      "avg / total       0.06      0.25      0.10      2495\n",
      "\n",
      "\n",
      "Logistic regression using raw pixel features:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       620\n",
      "          1       1.00      1.00      1.00       627\n",
      "          2       1.00      1.00      1.00       628\n",
      "          3       1.00      1.00      1.00       620\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2495\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zackb\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "rbm.n_components = 300\n",
    "logr.C = 6000\n",
    "\n",
    "# Training RBM-Logistic Pipeline\n",
    "classifier.fit(train_data, train_labels)\n",
    "\n",
    "# Training Logistic regression\n",
    "logistic_classifier = linear_model.LogisticRegression(C=500)\n",
    "logistic_classifier.fit(train_data, train_labels)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Logistic regression using RBM features:\\n%s\\n\" % (\n",
    "    metrics.classification_report(\n",
    "        test_labels,\n",
    "        classifier.predict(test_data))))\n",
    "\n",
    "print(\"Logistic regression using raw pixel features:\\n%s\\n\" % (\n",
    "    metrics.classification_report(\n",
    "        test_labels,\n",
    "        logistic_classifier.predict(test_data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zackb\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "#change labels to categorical\n",
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels)\n",
    "train_labels_one_hot = to_categorical(train_labels)\n",
    "test_labels_one_hot = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine the number of classes\n",
    "classes = np.unique(train_labels)\n",
    "nClasses  = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12475 samples, validate on 2495 samples\n",
      "Epoch 1/10\n",
      "12475/12475 [==============================] - 2s 166us/step - loss: 1.4426 - acc: 0.2837 - val_loss: 1.3240 - val_acc: 0.3651\n",
      "Epoch 2/10\n",
      "12475/12475 [==============================] - 2s 129us/step - loss: 1.1348 - acc: 0.4015 - val_loss: 0.7034 - val_acc: 0.5102\n",
      "Epoch 3/10\n",
      "12475/12475 [==============================] - 2s 128us/step - loss: 0.8118 - acc: 0.5473 - val_loss: 0.6102 - val_acc: 0.6497\n",
      "Epoch 4/10\n",
      "12475/12475 [==============================] - 2s 130us/step - loss: 0.7322 - acc: 0.6022 - val_loss: 0.5103 - val_acc: 0.6958\n",
      "Epoch 5/10\n",
      "12475/12475 [==============================] - 2s 131us/step - loss: 0.6664 - acc: 0.6873 - val_loss: 0.3507 - val_acc: 0.9375\n",
      "Epoch 6/10\n",
      "12475/12475 [==============================] - 2s 132us/step - loss: 0.4984 - acc: 0.8021 - val_loss: 0.1571 - val_acc: 0.9852\n",
      "Epoch 7/10\n",
      "12475/12475 [==============================] - 2s 130us/step - loss: 0.4337 - acc: 0.8561 - val_loss: 0.1629 - val_acc: 0.9731\n",
      "Epoch 8/10\n",
      "12475/12475 [==============================] - 2s 139us/step - loss: 0.3291 - acc: 0.9129 - val_loss: 0.9971 - val_acc: 0.6465\n",
      "Epoch 9/10\n",
      "12475/12475 [==============================] - 2s 143us/step - loss: 0.3973 - acc: 0.8706 - val_loss: 0.0632 - val_acc: 0.9860\n",
      "Epoch 10/10\n",
      "12475/12475 [==============================] - 2s 136us/step - loss: 0.2606 - acc: 0.9314 - val_loss: 0.0419 - val_acc: 0.9920\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "\n",
    "#three layers\n",
    "#activation function: both\n",
    "#neurons: 256\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation = 'tanh', input_shape = (dataDim,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(nClasses, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(train_data, train_labels_one_hot, batch_size = 256, epochs=10, verbose=1,\n",
    "                    validation_data=(test_data, test_labels_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2495/2495 [==============================] - 0s 67us/step\n",
      "Evaluation result on Test Data : Loss = 0.04192777874353221, accuracy = 0.9919839679358717\n"
     ]
    }
   ],
   "source": [
    "#test model\n",
    "[test_loss, test_acc] = model.evaluate(test_data, test_labels_one_hot)\n",
    "print(\"Evaluation result on Test Data : Loss = {}, accuracy = {}\".format(test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
